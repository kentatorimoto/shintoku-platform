import { AnnouncementScraper } from '../lib/scraper/announcements';

async function main() {
  console.log('ğŸš€ æ–°å¾—ç”ºãŠçŸ¥ã‚‰ã›ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹\n');

  const scraper = new AnnouncementScraper({
    baseUrl: process.env.BASE_URL || 'https://www.shintoku-town.jp',
  });

  try {
    const announcements = await scraper.scrapeList();
    
    console.log(`\nâœ… ${announcements.length}ä»¶ã®ãŠçŸ¥ã‚‰ã›ã‚’å–å¾—ã—ã¾ã—ãŸ\n`);
    
    // æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º
    announcements.slice(0, 5).forEach((announcement, index) => {
      console.log(`${index + 1}. ${announcement.title}`);
      console.log(`   æ—¥ä»˜: ${announcement.date}`);
      console.log(`   ã‚«ãƒ†ã‚´ãƒª: ${announcement.category}`);
      console.log(`   URL: ${announcement.url}`);
      console.log('');
    });

    // JSONå½¢å¼ã§ä¿å­˜
    const fs = require('fs');
    const path = require('path');
    
    const outputDir = path.join(process.cwd(), 'data', 'scraped');
    if (!fs.existsSync(outputDir)) {
      fs.mkdirSync(outputDir, { recursive: true });
    }

    const outputFile = path.join(outputDir, `announcements-${new Date().toISOString().split('T')[0]}.json`);
    fs.writeFileSync(outputFile, JSON.stringify(announcements, null, 2), 'utf-8');
    
    console.log(`ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: ${outputFile}`);

  } catch (error) {
    console.error('âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', error);
    process.exit(1);
  }
}

main();
